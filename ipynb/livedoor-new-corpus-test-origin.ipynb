{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing\n",
    "dirlist = [\"dokujo-tsushin\",\"it-life-hack\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abbdb4a2100d49ac8868d39d8cd4c0cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b3846c4a2ca41938428257e6d25b9b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=870), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6236746d94a74655b59fa9e456cabc78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=870), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=[\"class\",\"news\"])\n",
    "for i in tqdm(dirlist):\n",
    "    path = \"../japanese-dataset/livedoor-news-corpus/\"+i+\"/*.txt\"\n",
    "    files = glob.glob(path)\n",
    "    files.pop()\n",
    "    for j in tqdm(files):\n",
    "        f = open(j)\n",
    "        data = f.read() \n",
    "        f.close()\n",
    "        t = pd.Series([i,\"\".join(data.split(\"\\n\")[3:])],index = df.columns)\n",
    "        df  = df.append(t,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create word2vec\n",
    "import logging\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "import MeCab\n",
    "import time\n",
    "from sklearn.preprocessing import normalize\n",
    "import sys\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing sentences from training set...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "166d07eb66fb4d848297c977354077ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1740), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-05-30 08:25:51,046 : INFO : collecting all words and their counts\n",
      "2018-05-30 08:25:51,046 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Word2Vec model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-05-30 08:25:51,272 : INFO : collected 33912 word types from a corpus of 1139184 raw words and 1740 sentences\n",
      "2018-05-30 08:25:51,274 : INFO : Loading a fresh vocabulary\n",
      "2018-05-30 08:25:51,312 : INFO : min_count=20 retains 4722 unique words (13% of original 33912, drops 29190)\n",
      "2018-05-30 08:25:51,313 : INFO : min_count=20 leaves 1032246 word corpus (90% of original 1139184, drops 106938)\n",
      "2018-05-30 08:25:51,332 : INFO : deleting the raw counts dictionary of 33912 items\n",
      "2018-05-30 08:25:51,334 : INFO : sample=0.0001 downsamples 441 most-common words\n",
      "2018-05-30 08:25:51,334 : INFO : downsampling leaves estimated 462113 word corpus (44.8% of prior 1032246)\n",
      "2018-05-30 08:25:51,348 : INFO : estimated required memory for 4722 words and 100 dimensions: 6138600 bytes\n",
      "2018-05-30 08:25:51,349 : INFO : resetting layer weights\n",
      "2018-05-30 08:25:51,430 : INFO : training model with 8 workers on 4722 vocabulary and 100 features, using sg=1 hs=0 sample=0.0001 negative=10 window=10\n",
      "2018-05-30 08:25:52,463 : INFO : EPOCH 1 - PROGRESS: at 41.15% examples, 193865 words/s, in_qsize 15, out_qsize 0\n",
      "2018-05-30 08:25:53,515 : INFO : EPOCH 1 - PROGRESS: at 77.36% examples, 176041 words/s, in_qsize 15, out_qsize 0\n",
      "2018-05-30 08:25:53,835 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2018-05-30 08:25:53,885 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2018-05-30 08:25:53,900 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-05-30 08:25:53,925 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-05-30 08:25:53,936 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-05-30 08:25:53,937 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-05-30 08:25:53,946 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-05-30 08:25:53,948 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-05-30 08:25:53,949 : INFO : EPOCH - 1 : training on 1139184 raw words (462117 effective words) took 2.5s, 183700 effective words/s\n",
      "2018-05-30 08:25:53,951 : INFO : training on a 1139184 raw words (462117 effective words) took 2.5s, 183407 effective words/s\n",
      "2018-05-30 08:25:53,952 : INFO : precomputing L2-norms of word weight vectors\n",
      "2018-05-30 08:25:54,014 : INFO : saving Word2Vec object under ../japanese-dataset/livedoor-news-corpus/model/100features_20minwords_10context_len2alldata, separately None\n",
      "2018-05-30 08:25:54,015 : INFO : not storing attribute vectors_norm\n",
      "2018-05-30 08:25:54,016 : INFO : not storing attribute cum_table\n",
      "2018-05-30 08:25:54,070 : INFO : saved ../japanese-dataset/livedoor-news-corpus/model/100features_20minwords_10context_len2alldata\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Word2Vec model...\n",
      "time :  4.85810923576355\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "tokenizer =  MeCab.Tagger(\"-Owakati\")  \n",
    "sentences = []\n",
    "print (\"Parsing sentences from training set...\")\n",
    "\n",
    "# Loop over each news article.\n",
    "for review in tqdm(df[\"news\"]):\n",
    "    try:\n",
    "        # Split a review into parsed sentences.\n",
    "        result = tokenizer.parse(review).replace(\"\\u3000\",\"\").replace(\"\\n\",\"\")\n",
    "        result = re.sub(r'[0123456789０１２３４５６７８９！＠＃＄％＾＆\\-|\\\\＊\\“（）＿■×※⇒—●(：〜＋=)／*&^%$#@!~`){}…\\[\\]\\\"\\'\\”:;<>?＜＞？、。・,./『』【】「」→←○]+', \"\", result)\n",
    "        h = result.split(\" \")\n",
    "        h = list(filter((\"\").__ne__, h))\n",
    "        sentences.append(h)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s',\\\n",
    "    level=logging.INFO)\n",
    "\n",
    "num_features = 100     # Word vector dimensionality\n",
    "min_word_count = 20   # Minimum word count\n",
    "num_workers = 8       # Number of threads to run in parallel\n",
    "context = 10          # Context window size\n",
    "downsampling = 1e-4   # Downsample setting for frequent words\n",
    "\n",
    "print (\"Training Word2Vec model...\")\n",
    "# Train Word2Vec model.\n",
    "model = Word2Vec(sentences, workers=num_workers, hs = 0, sg = 1, negative = 10, iter = 1,\\\n",
    "            size=num_features, min_count = min_word_count, \\\n",
    "            window = context, sample = downsampling, seed=1)\n",
    "\n",
    "model_name = str(num_features) + \"features_\" + str(min_word_count) + \"minwords_\" + str(context) + \"context_len2alldata\"\n",
    "model.init_sims(replace=True)\n",
    "# Save Word2Vec model.\n",
    "print (\"Saving Word2Vec model...\")\n",
    "model.save(\"../japanese-dataset/livedoor-news-corpus/model/\"+model_name)\n",
    "endmodeltime = time.time()\n",
    "\n",
    "print (\"time : \", endmodeltime-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-05-30 08:25:54,077 : INFO : storing 4722x100 projection weights into ~/Downloads/testw2v.txt\n"
     ]
    }
   ],
   "source": [
    "model.wv.save_word2vec_format(\"~/Downloads/testw2v.txt\",binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create gwbowv\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,HashingVectorizer\n",
    "import pickle\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drange(start, stop, step):\n",
    "    r = start\n",
    "    while r < stop:\n",
    "        yield r\n",
    "        r += step\n",
    "\n",
    "def cluster_GMM(num_clusters, word_vectors):\n",
    "    # Initalize a GMM object and use it for clustering.\n",
    "    clf =  GaussianMixture(n_components=num_clusters,\n",
    "                    covariance_type=\"tied\", init_params='kmeans', max_iter=50)\n",
    "    # Get cluster assignments.\n",
    "    clf.fit(word_vectors)\n",
    "    idx = clf.predict(word_vectors)\n",
    "    print (\"Clustering Done...\", time.time()-start, \"seconds\")\n",
    "    # Get probabilities of cluster assignments.\n",
    "    idx_proba = clf.predict_proba(word_vectors)\n",
    "    # Dump cluster assignments and probability of cluster assignments. \n",
    "    pickle.dump(idx, open('../japanese-dataset/livedoor-news-corpus/model/gmm_latestclusmodel_len2alldata.pkl',\"wb\"))\n",
    "    print (\"Cluster Assignments Saved...\")\n",
    "\n",
    "    pickle.dump(idx_proba,open( '../japanese-dataset/livedoor-news-corpus/model/gmm_prob_latestclusmodel_len2alldata.pkl',\"wb\"))\n",
    "    print (\"Probabilities of Cluster Assignments Saved...\")\n",
    "    return (idx, idx_proba)\n",
    "\n",
    "def read_GMM(idx_name, idx_proba_name):\n",
    "    # Loads cluster assignments and probability of cluster assignments. \n",
    "    idx = pickle.load(open('../japanese-dataset/livedoor-news-corpus/model/gmm_latestclusmodel_len2alldata.pkl',\"rb\"))\n",
    "    idx_proba = pickle.load(open( '../japanese-dataset/livedoor-news-corpus/model/gmm_prob_latestclusmodel_len2alldata.pkl',\"rb\"))\n",
    "    print (\"Cluster Model Loaded...\")\n",
    "    return (idx, idx_proba)\n",
    "\n",
    "def get_probability_word_vectors(featurenames, model,word_centroid_map, num_clusters, word_idf_dict):\n",
    "    # This function computes probability word-cluster vectors\n",
    "    prob_wordvecs = {}\n",
    "    for word in word_centroid_map:\n",
    "        prob_wordvecs[word] = np.zeros( num_clusters * num_features, dtype=\"float32\" )\n",
    "        for index in range(0, num_clusters):\n",
    "            try:\n",
    "                prob_wordvecs[word][index*num_features:(index+1)*num_features] = model[word] * word_centroid_prob_map[word][index] * word_idf_dict[word]\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "    # prob_wordvecs_idf_len2alldata = {}\n",
    "    # i = 0\n",
    "    # for word in featurenames:\n",
    "    #     i += 1\n",
    "    #     if word in word_centroid_map:    \n",
    "    #         prob_wordvecs_idf_len2alldata[word] = {}\n",
    "    #         for index in range(0, num_clusters):\n",
    "    #                 prob_wordvecs_idf_len2alldata[word][index] = model[word] * word_centroid_prob_map[word][index] * word_idf_dict[word] \n",
    "\n",
    "    \n",
    "\n",
    "    # for word in prob_wordvecs_idf_len2alldata.keys():\n",
    "    #     prob_wordvecs[word] = prob_wordvecs_idf_len2alldata[word][0]\n",
    "    #     for index in prob_wordvecs_idf_len2alldata[word].keys():\n",
    "    #         if index==0:\n",
    "    #             continue\n",
    "    #         prob_wordvecs[word] = np.concatenate((prob_wordvecs[word], prob_wordvecs_idf_len2alldata[word][index]))\n",
    "    return prob_wordvecs\n",
    "\n",
    "def create_cluster_vector_and_gwbowv(prob_wordvecs, wordlist, word_centroid_map, word_centroid_prob_map, dimension, word_idf_dict, featurenames, num_centroids, train=False):\n",
    "    # This function computes SDV feature vectors.\n",
    "    # prob_wordvecs: estimated wordprob x idf value\n",
    "    # wordlist: words in test data as filter. but probably any type is OK\n",
    "    # word_centroid_map: dict {word:cluster}\n",
    "    # word_centroid_prob_map: dict{word:{probability in each cluster}}\n",
    "    # dimension: word vector dimention defined in word2vec estimation\n",
    "    # word_idf_dict: dict{word:idf} calcuated from all news\n",
    "    # featurenames:\n",
    "    # num_centroid:\n",
    "    bag_of_centroids = np.zeros( num_centroids * dimension, dtype=\"float32\" )\n",
    "    global min_no\n",
    "    global max_no\n",
    "\n",
    "    for word in wordlist:\n",
    "        try:\n",
    "            temp = word_centroid_map[word]\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        bag_of_centroids += prob_wordvecs[word]\n",
    "\n",
    "    norm = np.sqrt(np.einsum('...i,...i', bag_of_centroids, bag_of_centroids))\n",
    "    if(norm!=0):\n",
    "        bag_of_centroids /= norm\n",
    "\n",
    "    # To make feature vector sparse, make note of minimum and maximum values.\n",
    "    if train:\n",
    "        min_no += min(bag_of_centroids)\n",
    "        max_no += max(bag_of_centroids)\n",
    "\n",
    "    return bag_of_centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'100features_20minwords_10context_len2alldata'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-05-30 08:26:17,340 : INFO : loading Word2Vec object from ../japanese-dataset/livedoor-news-corpus/model/100features_20minwords_10context_len2alldata\n",
      "2018-05-30 08:26:17,380 : INFO : loading wv recursively from ../japanese-dataset/livedoor-news-corpus/model/100features_20minwords_10context_len2alldata.wv.* with mmap=None\n",
      "2018-05-30 08:26:17,381 : INFO : setting ignored attribute vectors_norm to None\n",
      "2018-05-30 08:26:17,381 : INFO : loading vocabulary recursively from ../japanese-dataset/livedoor-news-corpus/model/100features_20minwords_10context_len2alldata.vocabulary.* with mmap=None\n",
      "2018-05-30 08:26:17,382 : INFO : loading trainables recursively from ../japanese-dataset/livedoor-news-corpus/model/100features_20minwords_10context_len2alldata.trainables.* with mmap=None\n",
      "2018-05-30 08:26:17,383 : INFO : setting ignored attribute cum_table to None\n",
      "2018-05-30 08:26:17,384 : INFO : loaded ../japanese-dataset/livedoor-news-corpus/model/100features_20minwords_10context_len2alldata\n",
      "/Users/dmoriwaki/.pyenv/versions/3.6.5/lib/python3.6/site-packages/ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.wv.vectors instead).\n",
      "  \n",
      "/Users/dmoriwaki/.pyenv/versions/3.6.5/lib/python3.6/site-packages/sklearn/mixture/base.py:237: ConvergenceWarning: Initialization 1 did not converge. Try different init parameters, or increase max_iter, tol or check for degenerate data.\n",
      "  % (init + 1), ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering Done... 37.498635053634644 seconds\n",
      "Cluster Assignments Saved...\n",
      "Probabilities of Cluster Assignments Saved...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_name = str(num_features) + \"features_\" + str(min_word_count) + \"minwords_\" + str(context) + \"context_len2alldata\"\n",
    "# Load the trained Word2Vec model.\n",
    "model = Word2Vec.load(\"../japanese-dataset/livedoor-news-corpus/model/\"+model_name)\n",
    "# Get wordvectors for all words in vocabulary.\n",
    "word_vectors = model.wv.syn0\n",
    "\n",
    "# Load train data.\n",
    "train,test = train_test_split(df,test_size=0.3,random_state=40)\n",
    "all = df\n",
    "\n",
    "# Set number of clusters.\n",
    "num_clusters = 40\n",
    "# Uncomment below line for creating new clusters.\n",
    "idx, idx_proba = cluster_GMM(num_clusters, word_vectors)\n",
    "\n",
    "# Uncomment below lines for loading saved cluster assignments and probabaility of cluster assignments.\n",
    "# idx_name = \"gmm_latestclusmodel_len2alldata.pkl\"\n",
    "# idx_proba_name = \"gmm_prob_latestclusmodel_len2alldata.pkl\"\n",
    "# idx, idx_proba = read_GMM(idx_name, idx_proba_name)\n",
    "\n",
    "# Create a Word / Index dictionary, mapping each vocabulary word to\n",
    "# a cluster number\n",
    "word_centroid_map = dict(zip( model.wv.index2word, idx ))\n",
    "# Create a Word / Probability of cluster assignment dictionary, mapping each vocabulary word to\n",
    "# list of probabilities of cluster assignments.\n",
    "word_centroid_prob_map = dict(zip( model.wv.index2word, idx_proba ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating word-idf dictionary for Training set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dmoriwaki/.pyenv/versions/3.6.5/lib/python3.6/site-packages/ipykernel_launcher.py:39: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    }
   ],
   "source": [
    "# Computing tf-idf values.\n",
    "traindata = []\n",
    "for review in all[\"news\"]:\n",
    "    result = tokenizer.parse(review).replace(\"\\u3000\",\"\").replace(\"\\n\",\"\")\n",
    "    result = re.sub(r'[0123456789０１２３４５６７８９！＠＃＄％＾＆\\-|\\\\＊\\“（）＿■×※⇒—●(：〜＋=)／*&^%$#@!~`){}…\\[\\]\\\"\\'\\”:;<>?＜＞？、。・,./『』【】「」→←○]+', \"\", result)\n",
    "    h = result.split(\" \")\n",
    "    h = filter((\"\").__ne__, h)\n",
    "    traindata.append(\" \".join(h))\n",
    "\n",
    "tfv = TfidfVectorizer(dtype=np.float32)\n",
    "tfidfmatrix_traindata = tfv.fit_transform(traindata)\n",
    "featurenames = tfv.get_feature_names()\n",
    "idf = tfv._tfidf.idf_\n",
    "\n",
    "# Creating a dictionary with word mapped to its idf value \n",
    "print (\"Creating word-idf dictionary for Training set...\")\n",
    "\n",
    "word_idf_dict = {}\n",
    "for pair in zip(featurenames, idf):\n",
    "    word_idf_dict[pair[0]] = pair[1]\n",
    "    \n",
    "# Pre-computing probability word-cluster vectors.\n",
    "prob_wordvecs = get_probability_word_vectors(featurenames, model,word_centroid_map, num_clusters, word_idf_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'aa': 6.670455470540134,\n",
       " 'aaa': 7.36360265110008,\n",
       " 'aaaa': 7.7690677592082436,\n",
       " 'aac': 6.8527770273340884,\n",
       " 'aae': 7.7690677592082436,\n",
       " 'aat': 7.7690677592082436,\n",
       " 'ab': 7.7690677592082436,\n",
       " 'abc': 7.36360265110008,\n",
       " 'abcd': 7.7690677592082436,\n",
       " 'abee': 7.7690677592082436,\n",
       " 'abelia': 7.7690677592082436,\n",
       " 'about': 7.075920578648298,\n",
       " 'abs': 7.7690677592082436,\n",
       " 'ac': 4.851297027123964,\n",
       " 'aca': 7.7690677592082436,\n",
       " 'acadp': 7.7690677592082436,\n",
       " 'acc': 7.7690677592082436,\n",
       " 'accelerator': 7.7690677592082436,\n",
       " 'accelero': 7.7690677592082436,\n",
       " 'access': 7.7690677592082436,\n",
       " 'accs': 7.36360265110008,\n",
       " 'accsjp': 7.7690677592082436,\n",
       " 'ace': 7.7690677592082436,\n",
       " 'acer': 6.670455470540134,\n",
       " 'aceracer': 7.7690677592082436,\n",
       " 'ackposts': 7.7690677592082436,\n",
       " 'acl': 7.7690677592082436,\n",
       " 'acp': 7.7690677592082436,\n",
       " 'acro': 7.7690677592082436,\n",
       " 'acrobat': 7.7690677592082436,\n",
       " 'act': 7.7690677592082436,\n",
       " 'action': 7.7690677592082436,\n",
       " 'active': 7.36360265110008,\n",
       " 'activeimage': 7.7690677592082436,\n",
       " 'acts': 7.7690677592082436,\n",
       " 'actually': 7.7690677592082436,\n",
       " 'acu': 7.7690677592082436,\n",
       " 'acubic': 7.7690677592082436,\n",
       " 'ad': 6.8527770273340884,\n",
       " 'adapter': 7.36360265110008,\n",
       " 'adaptive': 7.36360265110008,\n",
       " 'add': 7.7690677592082436,\n",
       " 'adf': 7.075920578648298,\n",
       " 'admin': 7.7690677592082436,\n",
       " 'administrator': 7.7690677592082436,\n",
       " 'adobe': 6.5163047907128755,\n",
       " 'adrenaline': 7.7690677592082436,\n",
       " 'ads': 7.36360265110008,\n",
       " 'adsl': 6.8527770273340884,\n",
       " 'advanced': 7.36360265110008,\n",
       " 'adventures': 7.7690677592082436,\n",
       " 'ae': 7.36360265110008,\n",
       " 'aegislab': 7.7690677592082436,\n",
       " 'aerocool': 7.7690677592082436,\n",
       " 'aes': 7.7690677592082436,\n",
       " 'aesthetic': 7.7690677592082436,\n",
       " 'af': 6.670455470540134,\n",
       " 'affs': 7.7690677592082436,\n",
       " 'africa': 7.7690677592082436,\n",
       " 'african': 7.7690677592082436,\n",
       " 'afterburner': 7.7690677592082436,\n",
       " 'ag': 6.670455470540134,\n",
       " 'aga': 7.7690677592082436,\n",
       " 'agent': 7.7690677592082436,\n",
       " 'ages': 7.7690677592082436,\n",
       " 'agony': 7.7690677592082436,\n",
       " 'ah': 7.7690677592082436,\n",
       " 'aha': 7.7690677592082436,\n",
       " 'aibo': 7.36360265110008,\n",
       " 'aiguru': 7.7690677592082436,\n",
       " 'aiko': 7.7690677592082436,\n",
       " 'aio': 7.075920578648298,\n",
       " 'air': 5.371172486409873,\n",
       " 'airplay': 7.075920578648298,\n",
       " 'akai': 7.7690677592082436,\n",
       " 'akb': 5.629001595711973,\n",
       " 'akbingo': 7.7690677592082436,\n",
       " 'akiba': 5.897265582306653,\n",
       " 'akie': 7.7690677592082436,\n",
       " 'akiko': 7.7690677592082436,\n",
       " 'akimoto': 7.7690677592082436,\n",
       " 'al': 7.7690677592082436,\n",
       " 'album': 7.7690677592082436,\n",
       " 'alice': 7.36360265110008,\n",
       " 'alimo': 7.7690677592082436,\n",
       " 'all': 3.513455049390021,\n",
       " 'allow': 7.7690677592082436,\n",
       " 'already': 7.7690677592082436,\n",
       " 'alt': 6.670455470540134,\n",
       " 'altair': 7.7690677592082436,\n",
       " 'am': 7.075920578648298,\n",
       " 'amazing': 7.7690677592082436,\n",
       " 'amazon': 2.890060907590424,\n",
       " 'amba': 7.7690677592082436,\n",
       " 'amd': 5.243339114899988,\n",
       " 'amebagg': 7.7690677592082436,\n",
       " 'amen': 7.7690677592082436,\n",
       " 'amenfashion': 7.7690677592082436,\n",
       " 'american': 6.8527770273340884,\n",
       " 'amex': 7.7690677592082436,\n",
       " 'amoled': 7.36360265110008,\n",
       " 'amp': 6.8527770273340884,\n",
       " 'amplifier': 7.36360265110008,\n",
       " 'ampr': 7.7690677592082436,\n",
       " 'amzn': 7.7690677592082436,\n",
       " 'an': 6.8527770273340884,\n",
       " 'anan': 7.36360265110008,\n",
       " 'and': 5.82315761015293,\n",
       " 'andoird': 6.8527770273340884,\n",
       " 'andorid': 7.075920578648298,\n",
       " 'android': 3.42526233735456,\n",
       " 'androidjp': 7.7690677592082436,\n",
       " 'anecan': 7.7690677592082436,\n",
       " 'angeles': 7.7690677592082436,\n",
       " 'angry': 7.7690677592082436,\n",
       " 'angrybirds': 4.72454532148482,\n",
       " 'animal': 7.7690677592082436,\n",
       " 'anime': 7.7690677592082436,\n",
       " 'anjin': 7.7690677592082436,\n",
       " 'anodizing': 7.7690677592082436,\n",
       " 'anonymous': 6.064319666969818,\n",
       " 'anteeksi': 7.7690677592082436,\n",
       " 'anthy': 7.7690677592082436,\n",
       " 'anti': 7.7690677592082436,\n",
       " 'anywhere': 7.7690677592082436,\n",
       " 'ao': 7.36360265110008,\n",
       " 'ap': 7.075920578648298,\n",
       " 'apa': 7.7690677592082436,\n",
       " 'ape': 7.7690677592082436,\n",
       " 'apfu': 7.7690677592082436,\n",
       " 'api': 7.7690677592082436,\n",
       " 'app': 5.028227735283043,\n",
       " 'appcleaner': 7.36360265110008,\n",
       " 'applab': 7.7690677592082436,\n",
       " 'apple': 5.061017558106034,\n",
       " 'appleshowallfiles': 7.7690677592082436,\n",
       " 'applet': 7.7690677592082436,\n",
       " 'application': 7.36360265110008,\n",
       " 'applications': 7.7690677592082436,\n",
       " 'apply': 7.7690677592082436,\n",
       " 'apps': 7.7690677592082436,\n",
       " 'appstore': 6.670455470540134,\n",
       " 'apq': 7.7690677592082436,\n",
       " 'aps': 6.8527770273340884,\n",
       " 'apt': 7.7690677592082436,\n",
       " 'apu': 6.159629846774143,\n",
       " 'apz': 7.7690677592082436,\n",
       " 'aqua': 7.7690677592082436,\n",
       " 'aquarium': 7.7690677592082436,\n",
       " 'aquos': 4.851297027123964,\n",
       " 'ar': 6.670455470540134,\n",
       " 'arc': 7.7690677592082436,\n",
       " 'architecture': 7.36360265110008,\n",
       " 'archives': 6.382773398088353,\n",
       " 'arctic': 7.7690677592082436,\n",
       " 'are': 7.36360265110008,\n",
       " 'argo': 7.7690677592082436,\n",
       " 'arizona': 7.7690677592082436,\n",
       " 'arm': 6.8527770273340884,\n",
       " 'armband': 7.7690677592082436,\n",
       " 'arrandale': 7.7690677592082436,\n",
       " 'arrange': 7.7690677592082436,\n",
       " 'arrows': 5.629001595711973,\n",
       " 'arsock': 7.7690677592082436,\n",
       " 'art': 7.7690677592082436,\n",
       " 'arte': 7.7690677592082436,\n",
       " 'article': 6.670455470540134,\n",
       " 'arts': 7.7690677592082436,\n",
       " 'as': 7.36360265110008,\n",
       " 'ascend': 7.7690677592082436,\n",
       " 'ascii': 5.243339114899988,\n",
       " 'asha': 7.36360265110008,\n",
       " 'asian': 7.36360265110008,\n",
       " 'aska': 7.7690677592082436,\n",
       " 'asktech': 7.7690677592082436,\n",
       " 'aspherical': 7.7690677592082436,\n",
       " 'aspire': 7.36360265110008,\n",
       " 'asrock': 7.7690677592082436,\n",
       " 'association': 7.7690677592082436,\n",
       " 'assyra': 7.7690677592082436,\n",
       " 'asus': 5.897265582306653,\n",
       " 'asusasus': 7.36360265110008,\n",
       " 'asustek': 6.382773398088353,\n",
       " 'asv': 7.7690677592082436,\n",
       " 'at': 6.5163047907128755,\n",
       " 'ata': 7.36360265110008,\n",
       " 'atapi': 7.7690677592082436,\n",
       " 'atch': 7.7690677592082436,\n",
       " 'ath': 7.7690677592082436,\n",
       " 'atheros': 7.7690677592082436,\n",
       " 'atm': 7.36360265110008,\n",
       " 'atnd': 7.7690677592082436,\n",
       " 'atok': 7.36360265110008,\n",
       " 'atom': 5.82315761015293,\n",
       " 'attached': 7.7690677592082436,\n",
       " 'atx': 6.670455470540134,\n",
       " 'atxrb': 7.7690677592082436,\n",
       " 'au': 4.935854415152027,\n",
       " 'audio': 6.8527770273340884,\n",
       " 'aurasma': 7.7690677592082436,\n",
       " 'aurum': 7.7690677592082436,\n",
       " 'ausb': 7.36360265110008,\n",
       " 'australia': 7.7690677592082436,\n",
       " 'autonomy': 7.7690677592082436,\n",
       " 'autor': 7.7690677592082436,\n",
       " 'autoruns': 6.382773398088353,\n",
       " 'av': 5.571843181872024,\n",
       " 'ava': 7.7690677592082436,\n",
       " 'avago': 7.7690677592082436,\n",
       " 'avc': 7.36360265110008,\n",
       " 'avchd': 7.36360265110008,\n",
       " 'avg': 7.7690677592082436,\n",
       " 'avi': 6.8527770273340884,\n",
       " 'avrcp': 7.7690677592082436,\n",
       " 'avs': 7.36360265110008,\n",
       " 'aw': 7.7690677592082436,\n",
       " 'award': 7.36360265110008,\n",
       " 'ax': 7.7690677592082436,\n",
       " 'ay': 7.7690677592082436,\n",
       " 'ba': 7.7690677592082436,\n",
       " 'babbi': 7.7690677592082436,\n",
       " 'baby': 7.7690677592082436,\n",
       " 'back': 7.7690677592082436,\n",
       " 'backgrounds': 7.7690677592082436,\n",
       " 'bad': 7.075920578648298,\n",
       " 'bag': 7.7690677592082436,\n",
       " 'ban': 7.7690677592082436,\n",
       " 'banana': 7.7690677592082436,\n",
       " 'bank': 7.075920578648298,\n",
       " 'bar': 7.7690677592082436,\n",
       " 'barackobama': 7.7690677592082436,\n",
       " 'base': 7.075920578648298,\n",
       " 'bass': 7.36360265110008,\n",
       " 'bat': 7.7690677592082436,\n",
       " 'battery': 7.36360265110008,\n",
       " 'battle': 7.7690677592082436,\n",
       " 'bay': 7.7690677592082436,\n",
       " 'bazaar': 7.7690677592082436,\n",
       " 'bb': 6.670455470540134,\n",
       " 'bbmf': 7.7690677592082436,\n",
       " 'bbq': 7.7690677592082436,\n",
       " 'bbs': 7.7690677592082436,\n",
       " 'bci': 4.055495692503936,\n",
       " 'bct': 7.36360265110008,\n",
       " 'bd': 5.629001595711973,\n",
       " 'bdr': 7.7690677592082436,\n",
       " 'bdxl': 6.8527770273340884,\n",
       " 'be': 6.159629846774143,\n",
       " 'beanandroid': 7.7690677592082436,\n",
       " 'beans': 7.7690677592082436,\n",
       " 'beat': 7.36360265110008,\n",
       " 'beats': 7.7690677592082436,\n",
       " 'beauty': 7.7690677592082436,\n",
       " 'beautybar': 7.7690677592082436,\n",
       " 'because': 7.36360265110008,\n",
       " 'beetv': 6.5163047907128755,\n",
       " 'beeworks': 7.7690677592082436,\n",
       " 'bems': 7.7690677592082436,\n",
       " 'benq': 7.075920578648298,\n",
       " 'berryz': 7.36360265110008,\n",
       " 'beryyz': 7.7690677592082436,\n",
       " 'best': 6.8527770273340884,\n",
       " 'between': 7.7690677592082436,\n",
       " 'bf': 6.8527770273340884,\n",
       " 'bgm': 6.159629846774143,\n",
       " 'bicycle': 7.7690677592082436,\n",
       " 'big': 7.7690677592082436,\n",
       " 'biglobe': 7.36360265110008,\n",
       " 'bike': 7.36360265110008,\n",
       " 'bill': 7.7690677592082436,\n",
       " 'bing': 7.7690677592082436,\n",
       " 'bionz': 7.7690677592082436,\n",
       " 'bios': 6.064319666969818,\n",
       " 'biosii': 7.7690677592082436,\n",
       " 'birds': 7.7690677592082436,\n",
       " 'bit': 5.897265582306653,\n",
       " 'bitdefender': 7.7690677592082436,\n",
       " 'bittorrent': 7.7690677592082436,\n",
       " 'biz': 7.7690677592082436,\n",
       " 'bj': 7.7690677592082436,\n",
       " 'bk': 6.26499036243197,\n",
       " 'bl': 6.26499036243197,\n",
       " 'bla': 7.7690677592082436,\n",
       " 'black': 6.382773398088353,\n",
       " 'blackberry': 7.7690677592082436,\n",
       " 'blackcas': 7.7690677592082436,\n",
       " 'blade': 7.7690677592082436,\n",
       " 'blake': 7.7690677592082436,\n",
       " 'blasting': 7.7690677592082436,\n",
       " 'bleu': 7.7690677592082436,\n",
       " 'blog': 6.159629846774143,\n",
       " 'blokus': 7.7690677592082436,\n",
       " 'bloomberg': 7.7690677592082436,\n",
       " 'bloomfiled': 7.7690677592082436,\n",
       " 'blower': 7.7690677592082436,\n",
       " 'blu': 6.26499036243197,\n",
       " 'blue': 6.8527770273340884,\n",
       " 'bluetooth': 4.906866878278775,\n",
       " 'bluetoothr': 7.7690677592082436,\n",
       " 'bm': 7.7690677592082436,\n",
       " 'bmi': 7.7690677592082436,\n",
       " 'bmp': 7.36360265110008,\n",
       " 'bntj': 7.7690677592082436,\n",
       " 'boal': 7.7690677592082436,\n",
       " 'boardwalk': 7.7690677592082436,\n",
       " 'bomb': 7.7690677592082436,\n",
       " 'bond': 7.7690677592082436,\n",
       " 'booch': 7.7690677592082436,\n",
       " 'book': 6.5163047907128755,\n",
       " 'booklive': 7.7690677592082436,\n",
       " 'bookman': 7.7690677592082436,\n",
       " 'books': 7.36360265110008,\n",
       " 'bookworms': 7.7690677592082436,\n",
       " 'bool': 7.7690677592082436,\n",
       " 'boost': 6.5163047907128755,\n",
       " 'boot': 7.36360265110008,\n",
       " 'bootcamp': 7.7690677592082436,\n",
       " 'born': 7.7690677592082436,\n",
       " 'bot': 7.7690677592082436,\n",
       " 'box': 5.754164738665979,\n",
       " 'boy': 7.7690677592082436,\n",
       " 'boys': 7.7690677592082436,\n",
       " 'bpm': 7.36360265110008,\n",
       " 'brasero': 7.7690677592082436,\n",
       " 'bravia': 7.7690677592082436,\n",
       " 'break': 7.7690677592082436,\n",
       " 'breath': 7.7690677592082436,\n",
       " 'bridege': 6.8527770273340884,\n",
       " 'bridge': 5.16637807376386,\n",
       " 'brige': 7.7690677592082436,\n",
       " 'bright': 7.36360265110008,\n",
       " 'brilliance': 7.7690677592082436,\n",
       " 'bronze': 7.7690677592082436,\n",
       " 'bros': 7.075920578648298,\n",
       " 'brothers': 7.36360265110008,\n",
       " 'browserquest': 7.7690677592082436,\n",
       " 'brp': 7.075920578648298,\n",
       " 'brv': 7.7690677592082436,\n",
       " 'brxl': 7.7690677592082436,\n",
       " 'bs': 5.977308289980189,\n",
       " 'bsa': 7.7690677592082436,\n",
       " 'bscr': 7.7690677592082436,\n",
       " 'bscrd': 7.7690677592082436,\n",
       " 'bsp': 7.7690677592082436,\n",
       " 'bt': 7.075920578648298,\n",
       " 'bths': 7.7690677592082436,\n",
       " 'bto': 6.8527770273340884,\n",
       " 'btob': 6.8527770273340884,\n",
       " 'buffalo': 5.689626217528408,\n",
       " 'bulk': 7.7690677592082436,\n",
       " 'bullguard': 7.7690677592082436,\n",
       " 'bump': 7.36360265110008,\n",
       " 'burner': 7.7690677592082436,\n",
       " 'burst': 7.7690677592082436,\n",
       " 'bus': 7.7690677592082436,\n",
       " 'business': 7.075920578648298,\n",
       " 'busonera': 7.7690677592082436,\n",
       " 'but': 7.7690677592082436,\n",
       " 'butter': 7.7690677592082436,\n",
       " 'butterfly': 7.7690677592082436,\n",
       " 'buzzg': 7.7690677592082436,\n",
       " 'by': 4.824628780041803,\n",
       " 'bye': 7.36360265110008,\n",
       " 'ca': 7.36360265110008,\n",
       " 'cab': 7.7690677592082436,\n",
       " 'cabl': 7.7690677592082436,\n",
       " 'caches': 7.7690677592082436,\n",
       " 'cacheset': 6.670455470540134,\n",
       " 'cad': 7.7690677592082436,\n",
       " 'caddy': 7.7690677592082436,\n",
       " 'cafe': 5.571843181872024,\n",
       " 'caillou': 7.7690677592082436,\n",
       " 'calc': 7.36360265110008,\n",
       " 'calendar': 7.7690677592082436,\n",
       " 'callaghan': 7.7690677592082436,\n",
       " 'called': 7.7690677592082436,\n",
       " 'camera': 7.7690677592082436,\n",
       " 'camp': 7.36360265110008,\n",
       " 'campaign': 7.7690677592082436,\n",
       " 'campaigns': 7.7690677592082436,\n",
       " 'campfirejp': 7.7690677592082436,\n",
       " 'candid': 7.7690677592082436,\n",
       " 'canna': 7.36360265110008,\n",
       " 'canon': 7.7690677592082436,\n",
       " 'capture': 7.7690677592082436,\n",
       " 'car': 7.7690677592082436,\n",
       " 'carat': 7.7690677592082436,\n",
       " 'carbon': 6.8527770273340884,\n",
       " 'carboy': 7.7690677592082436,\n",
       " 'card': 7.7690677592082436,\n",
       " 'cardy': 7.7690677592082436,\n",
       " 'carrier': 7.7690677592082436,\n",
       " 'carry': 7.7690677592082436,\n",
       " 'cas': 6.159629846774143,\n",
       " 'casa': 7.7690677592082436,\n",
       " 'case': 6.5163047907128755,\n",
       " 'cases': 7.36360265110008,\n",
       " 'catalyst': 7.7690677592082436,\n",
       " 'catchnotes': 7.7690677592082436,\n",
       " 'category': 7.36360265110008,\n",
       " 'catv': 6.8527770273340884,\n",
       " 'cbs': 7.7690677592082436,\n",
       " 'cc': 7.075920578648298,\n",
       " 'ccd': 7.36360265110008,\n",
       " 'cd': 4.824628780041803,\n",
       " 'cdburnerxp': 7.7690677592082436,\n",
       " 'cdc': 7.075920578648298,\n",
       " 'ce': 7.36360265110008,\n",
       " 'cebell': 7.7690677592082436,\n",
       " 'cebit': 6.5163047907128755,\n",
       " 'celeblity': 7.7690677592082436,\n",
       " 'celeron': 7.7690677592082436,\n",
       " 'cell': 7.7690677592082436,\n",
       " 'center': 6.159629846774143,\n",
       " 'centerios': 7.7690677592082436,\n",
       " 'century': 7.36360265110008,\n",
       " 'ceo': 6.670455470540134,\n",
       " 'cert': 6.8527770273340884,\n",
       " 'certified': 7.7690677592082436,\n",
       " 'ces': 6.670455470540134,\n",
       " 'cf': 7.36360265110008,\n",
       " 'cg': 7.36360265110008,\n",
       " 'ch': 6.5163047907128755,\n",
       " 'cha': 7.7690677592082436,\n",
       " 'chage': 7.7690677592082436,\n",
       " 'chain': 7.7690677592082436,\n",
       " 'challenge': 6.26499036243197,\n",
       " 'change': 7.7690677592082436,\n",
       " 'channel': 7.7690677592082436,\n",
       " 'chaotic': 7.7690677592082436,\n",
       " 'chapter': 7.36360265110008,\n",
       " 'chara': 7.7690677592082436,\n",
       " 'charger': 7.075920578648298,\n",
       " 'check': 7.7690677592082436,\n",
       " 'checker': 7.36360265110008,\n",
       " 'cherryville': 6.8527770273340884,\n",
       " 'chevalier': 7.7690677592082436,\n",
       " 'child': 7.7690677592082436,\n",
       " 'chinese': 7.7690677592082436,\n",
       " 'choice': 7.7690677592082436,\n",
       " 'chokaigi': 7.7690677592082436,\n",
       " 'chrome': 5.326720723839039,\n",
       " 'cia': 7.7690677592082436,\n",
       " 'cintiq': 7.36360265110008,\n",
       " 'circle': 7.7690677592082436,\n",
       " 'cis': 7.7690677592082436,\n",
       " 'citation': 7.7690677592082436,\n",
       " 'city': 6.5163047907128755,\n",
       " 'cjlldr': 7.7690677592082436,\n",
       " 'ck': 7.7690677592082436,\n",
       " 'ckb': 7.7690677592082436,\n",
       " 'ckp': 7.7690677592082436,\n",
       " 'cl': 5.204118401746707,\n",
       " 'claimxav': 7.7690677592082436,\n",
       " 'clamxav': 7.36360265110008,\n",
       " 'clarity': 7.7690677592082436,\n",
       " 'class': 4.257522320377223,\n",
       " 'classic': 7.7690677592082436,\n",
       " 'cleanapp': 7.7690677592082436,\n",
       " 'clear': 7.36360265110008,\n",
       " 'clearly': 6.8527770273340884,\n",
       " 'client': 7.7690677592082436,\n",
       " 'clip': 6.5163047907128755,\n",
       " 'clipper': 7.7690677592082436,\n",
       " 'clis': 7.7690677592082436,\n",
       " 'clock': 7.36360265110008,\n",
       " 'clockwork': 7.7690677592082436,\n",
       " 'cloud': 6.5163047907128755,\n",
       " 'clouditunes': 7.7690677592082436,\n",
       " 'clover': 7.7690677592082436,\n",
       " 'cls': 7.7690677592082436,\n",
       " 'club': 7.7690677592082436,\n",
       " 'cm': 4.3678703775460885,\n",
       " 'cmd': 7.36360265110008,\n",
       " 'cmos': 6.382773398088353,\n",
       " 'cmosaf': 7.7690677592082436,\n",
       " 'cn': 7.7690677592082436,\n",
       " 'cnn': 7.7690677592082436,\n",
       " 'cnps': 7.7690677592082436,\n",
       " 'co': 2.9092553548465716,\n",
       " 'coalition': 7.36360265110008,\n",
       " 'cobs': 7.7690677592082436,\n",
       " 'cocohorader': 7.7690677592082436,\n",
       " 'college': 7.7690677592082436,\n",
       " 'color': 7.075920578648298,\n",
       " 'coloredge': 7.7690677592082436,\n",
       " 'coloring': 7.7690677592082436,\n",
       " 'com': 4.43686324903304,\n",
       " 'come': 7.075920578648298,\n",
       " 'comi': 7.7690677592082436,\n",
       " 'comic': 7.36360265110008,\n",
       " 'comicstudiopro': 7.7690677592082436,\n",
       " 'comid': 7.7690677592082436,\n",
       " 'coming': 7.36360265110008,\n",
       " 'command': 7.075920578648298,\n",
       " 'commerzbank': 7.7690677592082436,\n",
       " 'commondatakinds': 7.7690677592082436,\n",
       " 'communication': 7.36360265110008,\n",
       " 'community': 7.7690677592082436,\n",
       " 'company': 7.075920578648298,\n",
       " 'compaq': 7.7690677592082436,\n",
       " 'comparatives': 7.7690677592082436,\n",
       " 'composer': 7.7690677592082436,\n",
       " 'comptex': 6.159629846774143,\n",
       " 'comptia': 7.7690677592082436,\n",
       " 'computer': 7.36360265110008,\n",
       " 'computex': 6.670455470540134,\n",
       " 'computexe': 7.7690677592082436,\n",
       " 'con': 7.36360265110008,\n",
       " 'concepcion': 7.36360265110008,\n",
       " 'conference': 6.8527770273340884,\n",
       " 'conferences': 7.7690677592082436,\n",
       " 'congress': 7.7690677592082436,\n",
       " 'connect': 7.7690677592082436,\n",
       " 'conquest': 7.7690677592082436,\n",
       " 'conroe': 7.7690677592082436,\n",
       " 'contactscontract': 7.7690677592082436,\n",
       " 'contents': 6.8527770273340884,\n",
       " 'control': 7.075920578648298,\n",
       " 'controller': 7.7690677592082436,\n",
       " 'coo': 7.7690677592082436,\n",
       " 'cookie': 7.36360265110008,\n",
       " 'cookpad': 7.36360265110008,\n",
       " 'cool': 7.7690677592082436,\n",
       " 'cooler': 7.075920578648298,\n",
       " 'cooling': 7.7690677592082436,\n",
       " 'copyright': 3.9735785700360493,\n",
       " 'core': 4.530389307043864,\n",
       " 'corega': 7.7690677592082436,\n",
       " 'corp': 7.7690677592082436,\n",
       " 'corporation': 7.075920578648298,\n",
       " 'corridor': 7.7690677592082436,\n",
       " 'cospllection': 7.7690677592082436,\n",
       " 'cost': 7.7690677592082436,\n",
       " 'counta': 7.7690677592082436,\n",
       " 'countries': 7.7690677592082436,\n",
       " 'counts': 7.7690677592082436,\n",
       " 'cover': 7.075920578648298,\n",
       " 'cp': 7.7690677592082436,\n",
       " 'cpra': 7.7690677592082436,\n",
       " 'cprm': 7.7690677592082436,\n",
       " 'cpu': 3.929615446614933,\n",
       " 'cradle': 7.7690677592082436,\n",
       " 'cream': 7.7690677592082436,\n",
       " 'creative': 7.7690677592082436,\n",
       " 'creativecommons': 7.7690677592082436,\n",
       " 'cross': 7.7690677592082436,\n",
       " 'crossfire': 7.7690677592082436,\n",
       " 'crossfirex': 7.7690677592082436,\n",
       " 'crosu': 7.7690677592082436,\n",
       " 'crt': 7.36360265110008,\n",
       " 'crucial': 6.670455470540134,\n",
       " 'cruising': 7.7690677592082436,\n",
       " 'cryptome': 7.7690677592082436,\n",
       " 'crystal': 7.7690677592082436,\n",
       " 'cs': 6.064319666969818,\n",
       " 'cspi': 7.7690677592082436,\n",
       " 'csr': 7.7690677592082436,\n",
       " 'css': 7.7690677592082436,\n",
       " 'csv': 7.7690677592082436,\n",
       " 'ct': 7.075920578648298,\n",
       " 'ctee': 7.7690677592082436,\n",
       " 'cto': 7.36360265110008,\n",
       " 'ctrl': 6.670455470540134,\n",
       " 'cube': 5.243339114899988,\n",
       " 'cuda': 6.382773398088353,\n",
       " 'cui': 7.7690677592082436,\n",
       " 'culture': 7.075920578648298,\n",
       " 'curate': 7.7690677592082436,\n",
       " 'current': 7.7690677592082436,\n",
       " 'cut': 7.36360265110008,\n",
       " 'cutegirl': 7.7690677592082436,\n",
       " 'cutting': 7.7690677592082436,\n",
       " 'cve': 7.36360265110008,\n",
       " 'cvt': 7.7690677592082436,\n",
       " 'cw': 6.8527770273340884,\n",
       " 'cyber': 7.7690677592082436,\n",
       " 'cyberlink': 7.36360265110008,\n",
       " 'cybersecurity': 7.7690677592082436,\n",
       " 'da': 7.36360265110008,\n",
       " 'daisey': 7.7690677592082436,\n",
       " 'damien': 7.7690677592082436,\n",
       " 'dance': 7.7690677592082436,\n",
       " 'danceroid': 7.075920578648298,\n",
       " 'dark': 7.7690677592082436,\n",
       " 'dash': 6.8527770273340884,\n",
       " 'dat': 7.075920578648298,\n",
       " 'data': 5.094919109781715,\n",
       " 'dataplextm': 7.7690677592082436,\n",
       " 'date': 7.7690677592082436,\n",
       " 'daughter': 7.7690677592082436,\n",
       " 'day': 6.26499036243197,\n",
       " 'days': 6.5163047907128755,\n",
       " 'db': 6.670455470540134,\n",
       " 'dba': 6.8527770273340884,\n",
       " 'dbef': 7.7690677592082436,\n",
       " 'dc': 6.382773398088353,\n",
       " 'dcg': 7.7690677592082436,\n",
       " 'dd': 7.7690677592082436,\n",
       " 'ddr': 5.754164738665979,\n",
       " 'de': 7.075920578648298,\n",
       " 'death': 7.36360265110008,\n",
       " 'deb': 7.7690677592082436,\n",
       " 'debian': 7.7690677592082436,\n",
       " 'debit': 7.7690677592082436,\n",
       " 'debt': 7.7690677592082436,\n",
       " 'decker': 7.7690677592082436,\n",
       " 'deco': 7.36360265110008,\n",
       " 'deepburner': 7.7690677592082436,\n",
       " 'deeper': 7.7690677592082436,\n",
       " 'defaults': 7.7690677592082436,\n",
       " 'defense': 7.7690677592082436,\n",
       " 'defragment': 7.7690677592082436,\n",
       " 'dekyo': 7.7690677592082436,\n",
       " 'del': 7.36360265110008,\n",
       " 'delay': 7.7690677592082436,\n",
       " 'delete': 7.36360265110008,\n",
       " 'deli': 7.7690677592082436,\n",
       " 'dell': 6.670455470540134,\n",
       " 'delta': 7.7690677592082436,\n",
       " 'deluxe': 7.36360265110008,\n",
       " 'dena': 7.075920578648298,\n",
       " 'depper': 7.7690677592082436,\n",
       " 'derosa': 5.689626217528408,\n",
       " 'design': 7.7690677592082436,\n",
       " 'designer': 7.7690677592082436,\n",
       " 'detail': 6.382773398088353,\n",
       " 'details': 7.7690677592082436,\n",
       " 'developer': 7.36360265110008,\n",
       " 'developers': 7.075920578648298,\n",
       " 'device': 7.7690677592082436,\n",
       " 'df': 7.7690677592082436,\n",
       " 'dfs': 7.36360265110008,\n",
       " 'dgr': 7.075920578648298,\n",
       " 'dhc': 7.7690677592082436,\n",
       " 'dhs': 7.7690677592082436,\n",
       " 'di': 7.7690677592082436,\n",
       " 'diamond': 7.7690677592082436,\n",
       " 'diary': 7.7690677592082436,\n",
       " 'dict': 7.7690677592082436,\n",
       " 'difficult': 7.7690677592082436,\n",
       " 'dig': 7.7690677592082436,\n",
       " 'digaward': 7.7690677592082436,\n",
       " 'digi': 3.564375139817278,\n",
       " 'digic': 7.36360265110008,\n",
       " 'digion': 7.36360265110008,\n",
       " 'digital': 5.571843181872024,\n",
       " 'digno': 7.7690677592082436,\n",
       " 'dimm': 7.075920578648298,\n",
       " 'direct': 7.7690677592082436,\n",
       " 'directplus': 7.7690677592082436,\n",
       " 'directx': 7.36360265110008,\n",
       " 'dirt': 7.7690677592082436,\n",
       " 'disc': 7.7690677592082436,\n",
       " 'disk': 6.382773398088353,\n",
       " 'diskdropbox': 7.7690677592082436,\n",
       " 'diskeeper': 7.7690677592082436,\n",
       " 'diskview': 6.26499036243197,\n",
       " 'dispalyport': 7.7690677592082436,\n",
       " 'display': 7.7690677592082436,\n",
       " 'displaydock': 7.7690677592082436,\n",
       " 'displayport': 6.382773398088353,\n",
       " 'distributed': 7.7690677592082436,\n",
       " 'dixim': 6.8527770273340884,\n",
       " 'diy': 7.36360265110008,\n",
       " 'dj': 7.36360265110008,\n",
       " 'dk': 7.7690677592082436,\n",
       " 'dl': 6.159629846774143,\n",
       " 'dll': 7.7690677592082436,\n",
       " 'dlna': 7.075920578648298,\n",
       " 'dlp': 7.36360265110008,\n",
       " 'dlw': 7.7690677592082436,\n",
       " 'dm': 6.382773398088353,\n",
       " 'dmark': 7.7690677592082436,\n",
       " 'dmc': 7.36360265110008,\n",
       " 'dmm': 7.36360265110008,\n",
       " 'dna': 7.36360265110008,\n",
       " 'dns': 7.36360265110008,\n",
       " 'dnschanger': 7.7690677592082436,\n",
       " 'do': 7.075920578648298,\n",
       " 'doc': 7.7690677592082436,\n",
       " 'dock': 5.571843181872024,\n",
       " 'docomo': 5.689626217528408,\n",
       " 'docs': 7.36360265110008,\n",
       " 'document': 7.36360265110008,\n",
       " 'documentary': 7.36360265110008,\n",
       " 'documents': 7.7690677592082436,\n",
       " 'doers': 7.7690677592082436,\n",
       " 'doga': 7.7690677592082436,\n",
       " 'dokujo': 6.8527770273340884,\n",
       " 'dokuro': 7.7690677592082436,\n",
       " 'dom': 7.7690677592082436,\n",
       " 'don': 6.8527770273340884,\n",
       " 'donut': 7.7690677592082436,\n",
       " 'door': 7.7690677592082436,\n",
       " 'doplr': 7.7690677592082436,\n",
       " 'doriko': 7.7690677592082436,\n",
       " 'dosomething': 7.7690677592082436,\n",
       " 'dota': 7.7690677592082436,\n",
       " 'douga': 7.7690677592082436,\n",
       " 'dougalek': 7.7690677592082436,\n",
       " 'doughnuts': 6.670455470540134,\n",
       " 'downlink': 7.7690677592082436,\n",
       " 'download': 7.36360265110008,\n",
       " 'downloaded': 7.7690677592082436,\n",
       " 'downloader': 7.7690677592082436,\n",
       " 'dp': 6.5163047907128755,\n",
       " 'dpi': 6.670455470540134,\n",
       " 'dpkg': 7.7690677592082436,\n",
       " 'dqn': 6.8527770273340884,\n",
       " 'dr': 6.064319666969818,\n",
       " 'drake': 7.7690677592082436,\n",
       " 'dram': 6.8527770273340884,\n",
       " 'dramatic': 7.7690677592082436,\n",
       " 'draw': 7.36360265110008,\n",
       " 'drawing': 7.7690677592082436,\n",
       " 'dream': 6.5163047907128755,\n",
       " 'dreamcolor': 7.7690677592082436,\n",
       " 'dreams': 7.36360265110008,\n",
       " 'dreamweaver': 7.7690677592082436,\n",
       " 'dressing': 7.7690677592082436,\n",
       " 'drink': 7.7690677592082436,\n",
       " 'drive': 5.417692502044766,\n",
       " 'drivers': 7.7690677592082436,\n",
       " 'drm': 6.8527770273340884,\n",
       " 'dropbox': 4.906866878278775,\n",
       " 'droplr': 6.5163047907128755,\n",
       " 'dropper': 7.7690677592082436,\n",
       " 'ds': 5.326720723839039,\n",
       " 'dsc': 7.7690677592082436,\n",
       " 'dsp': 7.075920578648298,\n",
       " 'dt': 7.36360265110008,\n",
       " 'dtc': 7.7690677592082436,\n",
       " 'dtcp': 6.5163047907128755,\n",
       " 'dtp': 7.7690677592082436,\n",
       " 'dual': 6.382773398088353,\n",
       " 'duck': 7.7690677592082436,\n",
       " 'dude': 7.7690677592082436,\n",
       " 'duet': 7.7690677592082436,\n",
       " 'dunk': 7.7690677592082436,\n",
       " 'duo': 7.075920578648298,\n",
       " 'durable': 7.075920578648298,\n",
       " 'durex': 7.7690677592082436,\n",
       " 'dv': 7.075920578648298,\n",
       " 'dvd': 4.3678703775460885,\n",
       " 'dvddrive': 7.7690677592082436,\n",
       " 'dvi': 5.897265582306653,\n",
       " 'dvr': 7.7690677592082436,\n",
       " 'dvsm': 7.7690677592082436,\n",
       " 'dx': 7.075920578648298,\n",
       " 'dxl': 7.7690677592082436,\n",
       " 'dynabook': 7.7690677592082436,\n",
       " 'ea': 6.8527770273340884,\n",
       " 'eagle': 4.701014824074626,\n",
       " 'early': 7.7690677592082436,\n",
       " 'ebisubashi': 7.7690677592082436,\n",
       " 'ec': 6.670455470540134,\n",
       " 'echika': 7.7690677592082436,\n",
       " 'echo': 7.7690677592082436,\n",
       " 'echonet': 7.7690677592082436,\n",
       " 'eclair': 7.7690677592082436,\n",
       " 'ecs': 6.8527770273340884,\n",
       " 'ecstasy': 7.7690677592082436,\n",
       " 'ed': 7.7690677592082436,\n",
       " 'eden': 7.7690677592082436,\n",
       " 'edge': 7.075920578648298,\n",
       " 'edition': 5.82315761015293,\n",
       " 'editor': 7.7690677592082436,\n",
       " 'editors': 7.7690677592082436,\n",
       " 'edr': 7.7690677592082436,\n",
       " 'edu': 7.36360265110008,\n",
       " 'educational': 7.7690677592082436,\n",
       " 'edutech': 7.7690677592082436,\n",
       " 'eee': 7.075920578648298,\n",
       " 'eeepc': 7.36360265110008,\n",
       " 'ef': 7.36360265110008,\n",
       " 'effects': 7.7690677592082436,\n",
       " 'efi': 7.7690677592082436,\n",
       " 'efrx': 7.7690677592082436,\n",
       " 'egf': 7.7690677592082436,\n",
       " 'eico': 7.7690677592082436,\n",
       " 'eight': 7.7690677592082436,\n",
       " 'ekot': 7.36360265110008,\n",
       " 'el': 6.064319666969818,\n",
       " 'elecom': 7.36360265110008,\n",
       " 'electronics': 7.36360265110008,\n",
       " 'elite': 7.7690677592082436,\n",
       " 'elle': 7.7690677592082436,\n",
       " 'ellehttp': 7.7690677592082436,\n",
       " 'em': 7.7690677592082436,\n",
       " 'email': 7.7690677592082436,\n",
       " 'emery': 7.7690677592082436,\n",
       " 'emm': 7.7690677592082436,\n",
       " 'emobile': 7.36360265110008,\n",
       " 'emotion': 7.7690677592082436,\n",
       " 'empathy': 7.7690677592082436,\n",
       " 'empire': 7.7690677592082436,\n",
       " 'empty': 7.7690677592082436,\n",
       " 'en': 7.7690677592082436,\n",
       " 'end': 7.7690677592082436,\n",
       " 'endeavor': 7.36360265110008,\n",
       " 'endpoint': 7.7690677592082436,\n",
       " 'energy': 7.36360265110008,\n",
       " 'energyjp': 7.7690677592082436,\n",
       " 'engadget': 7.7690677592082436,\n",
       " 'engine': 7.7690677592082436,\n",
       " 'english': 7.7690677592082436,\n",
       " 'enix': 7.7690677592082436,\n",
       " 'enter': 5.897265582306653,\n",
       " 'entertainment': 6.670455470540134,\n",
       " 'entertainments': 7.7690677592082436,\n",
       " 'entiny': 7.7690677592082436,\n",
       " 'entry': 7.36360265110008,\n",
       " 'environment': 7.7690677592082436,\n",
       " 'envy': 6.159629846774143,\n",
       " 'eo': 7.36360265110008,\n",
       " 'eos': 6.8527770273340884,\n",
       " 'ep': 6.8527770273340884,\n",
       " 'epc': 7.7690677592082436,\n",
       " 'epg': 7.7690677592082436,\n",
       " 'epson': 7.7690677592082436,\n",
       " 'epub': 7.36360265110008,\n",
       " 'era': 7.7690677592082436,\n",
       " 'erase': 7.7690677592082436,\n",
       " 'ericsson': 7.7690677592082436,\n",
       " 'es': 5.977308289980189,\n",
       " 'esata': 6.159629846774143,\n",
       " 'esc': 7.36360265110008,\n",
       " 'escala': 7.7690677592082436,\n",
       " 'esd': 7.7690677592082436,\n",
       " 'eset': 7.075920578648298,\n",
       " 'eshop': 7.7690677592082436,\n",
       " 'esprimo': 7.7690677592082436,\n",
       " 'essid': 7.7690677592082436,\n",
       " 'etc': 5.243339114899988,\n",
       " 'etf': 7.7690677592082436,\n",
       " 'ethernet': 7.7690677592082436,\n",
       " 'etwy': 7.7690677592082436,\n",
       " 'eu': 6.159629846774143,\n",
       " 'europe': 7.7690677592082436,\n",
       " 'europeo': 7.7690677592082436,\n",
       " 'event': 7.36360265110008,\n",
       " 'eventatnd': 7.7690677592082436,\n",
       " 'everest': 7.7690677592082436,\n",
       " 'evernote': 5.571843181872024,\n",
       " 'every': 7.7690677592082436,\n",
       " 'evolution': 7.36360265110008,\n",
       " 'ex': 6.159629846774143,\n",
       " 'example': 7.7690677592082436,\n",
       " 'excel': 3.9735785700360493,\n",
       " 'exchange': 7.36360265110008,\n",
       " 'exe': 6.5163047907128755,\n",
       " 'executed': 7.7690677592082436,\n",
       " 'exfat': 7.7690677592082436,\n",
       " 'exilim': 7.7690677592082436,\n",
       " 'exit': 7.7690677592082436,\n",
       " 'exlorer': 7.7690677592082436,\n",
       " 'exmor': 7.075920578648298,\n",
       " 'exogear': 7.7690677592082436,\n",
       " 'exovolt': 7.7690677592082436,\n",
       " 'experimental': 7.7690677592082436,\n",
       " 'experss': 7.7690677592082436,\n",
       " 'explorer': 5.417692502044766,\n",
       " 'explzh': 7.7690677592082436,\n",
       " 'expo': 7.36360265110008,\n",
       " 'express': 5.204118401746707,\n",
       " 'external': 7.36360265110008,\n",
       " 'extra': 7.36360265110008,\n",
       " 'extreme': 6.670455470540134,\n",
       " 'eye': 7.7690677592082436,\n",
       " 'ezweb': 7.7690677592082436,\n",
       " 'face': 7.36360265110008,\n",
       " 'facebook': 3.4924016401921887,\n",
       " 'facechange': 7.7690677592082436,\n",
       " 'factory': 7.36360265110008,\n",
       " 'fairy': 7.7690677592082436,\n",
       " 'fall': 7.7690677592082436,\n",
       " 'fan': 7.36360265110008,\n",
       " 'fancl': 7.7690677592082436,\n",
       " 'fancy': 7.7690677592082436,\n",
       " 'fanless': 7.7690677592082436,\n",
       " 'fantabit': 7.36360265110008,\n",
       " 'faq': 7.36360265110008,\n",
       " 'fashiolista': 7.7690677592082436,\n",
       " 'fashion': 7.7690677592082436,\n",
       " 'fast': 7.7690677592082436,\n",
       " 'fat': 7.075920578648298,\n",
       " 'fatal': 7.7690677592082436,\n",
       " 'fate': 7.7690677592082436,\n",
       " 'fax': 6.5163047907128755,\n",
       " 'fb': 6.5163047907128755,\n",
       " 'fbi': 5.977308289980189,\n",
       " 'fc': 6.8527770273340884,\n",
       " 'fd': 7.7690677592082436,\n",
       " 'fdb': 7.7690677592082436,\n",
       " 'fdc': 7.7690677592082436,\n",
       " 'fdd': 7.7690677592082436,\n",
       " 'feature': 7.36360265110008,\n",
       " 'fedra': 7.7690677592082436,\n",
       " 'feed': 7.7690677592082436,\n",
       " 'feel': 5.82315761015293,\n",
       " 'felica': 7.36360265110008,\n",
       " 'felt': 7.7690677592082436,\n",
       " 'fenrir': 7.7690677592082436,\n",
       " 'fermi': 6.26499036243197,\n",
       " 'ferrari': 7.7690677592082436,\n",
       " 'fes': 7.075920578648298,\n",
       " 'festival': 7.7690677592082436,\n",
       " 'ff': 6.670455470540134,\n",
       " 'fff': 7.7690677592082436,\n",
       " 'ffp': 4.105506113078597,\n",
       " 'ffxi': 7.7690677592082436,\n",
       " 'fg': 7.7690677592082436,\n",
       " 'fgm': 7.7690677592082436,\n",
       " 'fhm': 7.7690677592082436,\n",
       " 'fi': 4.678025305849928,\n",
       " 'field': 7.7690677592082436,\n",
       " 'fifa': 7.7690677592082436,\n",
       " 'file': 7.36360265110008,\n",
       " 'fileagentver': 7.7690677592082436,\n",
       " 'files': 7.075920578648298,\n",
       " 'filevault': 7.7690677592082436,\n",
       " 'filipino': 6.670455470540134,\n",
       " 'fill': 7.7690677592082436,\n",
       " 'film': 7.7690677592082436,\n",
       " 'films': 6.8527770273340884,\n",
       " 'final': 7.7690677592082436,\n",
       " 'findandcall': 7.7690677592082436,\n",
       " 'finder': 6.5163047907128755,\n",
       " 'fine': 7.7690677592082436,\n",
       " 'fire': 7.075920578648298,\n",
       " 'firefox': 5.204118401746707,\n",
       " 'firefoxfirefox': 7.7690677592082436,\n",
       " 'firehttp': 7.7690677592082436,\n",
       " 'firewire': 7.36360265110008,\n",
       " 'first': 7.7690677592082436,\n",
       " 'fish': 7.7690677592082436,\n",
       " 'fit': 7.7690677592082436,\n",
       " 'fitm': 7.7690677592082436,\n",
       " 'flac': 7.7690677592082436,\n",
       " 'flare': 7.7690677592082436,\n",
       " 'flash': 6.5163047907128755,\n",
       " 'flashairtm': 7.7690677592082436,\n",
       " 'flashback': 7.36360265110008,\n",
       " 'flashing': 7.7690677592082436,\n",
       " 'flex': 7.7690677592082436,\n",
       " 'flexr': 7.7690677592082436,\n",
       " 'flickr': 7.7690677592082436,\n",
       " 'flight': 7.36360265110008,\n",
       " 'floating': 7.7690677592082436,\n",
       " 'flower': 6.5163047907128755,\n",
       " 'flowers': 7.7690677592082436,\n",
       " 'fluzo': 7.7690677592082436,\n",
       " 'flv': 7.36360265110008,\n",
       " 'fly': 7.7690677592082436,\n",
       " 'fm': 7.36360265110008,\n",
       " 'fmpj': 7.7690677592082436,\n",
       " 'fmv': 7.36360265110008,\n",
       " 'folio': 6.064319666969818,\n",
       " 'foma': 6.5163047907128755,\n",
       " 'fon': 7.7690677592082436,\n",
       " 'food': 7.7690677592082436,\n",
       " 'for': 4.3678703775460885,\n",
       " 'force': 7.7690677592082436,\n",
       " 'format': 7.36360265110008,\n",
       " 'forza': 7.7690677592082436,\n",
       " 'fotografia': 7.7690677592082436,\n",
       " 'foveon': 7.36360265110008,\n",
       " 'fox': 6.8527770273340884,\n",
       " 'foxconn': 7.36360265110008,\n",
       " 'foxit': 7.36360265110008,\n",
       " 'fp': 7.7690677592082436,\n",
       " 'fps': 5.977308289980189,\n",
       " 'fpsgtx': 7.7690677592082436,\n",
       " 'fpsgun': 7.7690677592082436,\n",
       " 'fq': 7.7690677592082436,\n",
       " 'fr': 7.7690677592082436,\n",
       " 'framework': 7.7690677592082436,\n",
       " 'frankie': 7.7690677592082436,\n",
       " 'free': 7.7690677592082436,\n",
       " 'freehand': 7.7690677592082436,\n",
       " 'frequency': 7.7690677592082436,\n",
       " 'frick': 7.7690677592082436,\n",
       " 'friends': 7.7690677592082436,\n",
       " 'from': 7.36360265110008,\n",
       " 'froyo': 7.7690677592082436,\n",
       " 'frozr': 7.36360265110008,\n",
       " 'ft': 7.7690677592082436,\n",
       " 'ftth': 7.7690677592082436,\n",
       " 'fucking': 7.7690677592082436,\n",
       " 'fugitive': 7.7690677592082436,\n",
       " 'full': 7.36360265110008,\n",
       " 'fun': 6.8527770273340884,\n",
       " 'function': 7.7690677592082436,\n",
       " 'funds': 7.7690677592082436,\n",
       " 'fusion': 6.064319666969818,\n",
       " 'future': 7.7690677592082436,\n",
       " 'fwvga': 7.7690677592082436,\n",
       " 'fx': 6.8527770273340884,\n",
       " 'fxaa': 7.7690677592082436,\n",
       " ...}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_idf_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f05cc58ed89b4cff8cbf0dd29e3740a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4722), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "## for gensim keyedvectors\n",
    "file = open('../japanese-dataset/livedoor-news-corpus/model/temp2.txt', 'w')\n",
    "string_list = [str(len(prob_wordvecs)),str(len(list(prob_wordvecs.values())[0]))]\n",
    "string_list.append(\"\\n\")\n",
    "file.writelines(\" \".join(string_list))\n",
    "for key,value in tqdm(prob_wordvecs.items()):\n",
    "    string_list = []\n",
    "    string_list.append(key)\n",
    "    for i in value:\n",
    "        string_list.append(str(i))\n",
    "    string_list.append(\"\\n\")\n",
    "    file.writelines(\" \".join(string_list))\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-05-30 08:27:10,604 : INFO : loading projection weights from ../japanese-dataset/livedoor-news-corpus/model/temp2.txt\n",
      "2018-05-30 08:27:29,254 : INFO : loaded (4722, 4000) matrix from ../japanese-dataset/livedoor-news-corpus/model/temp2.txt\n",
      "2018-05-30 08:27:29,255 : INFO : saving Word2VecKeyedVectors object under ../japanese-dataset/livedoor-news-corpus/model/vector-response-test/word2vec_weighted.model, separately None\n",
      "2018-05-30 08:27:29,256 : INFO : storing np array 'vectors' to ../japanese-dataset/livedoor-news-corpus/model/vector-response-test/word2vec_weighted.model.vectors.npy\n",
      "2018-05-30 08:27:29,312 : INFO : not storing attribute vectors_norm\n",
      "2018-05-30 08:27:29,331 : INFO : saved ../japanese-dataset/livedoor-news-corpus/model/vector-response-test/word2vec_weighted.model\n"
     ]
    }
   ],
   "source": [
    "word2vec_weighted = KeyedVectors.load_word2vec_format(\"../japanese-dataset/livedoor-news-corpus/model/temp2.txt\",binary=False)\n",
    "word2vec_weighted.save(\"../japanese-dataset/livedoor-news-corpus/model/vector-response-test/word2vec_weighted.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(prob_wordvecs,open(\"../japanese-dataset/livedoor-news-corpus/model/prob_wordvecs.pkl\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train News Covered :  1000\n"
     ]
    }
   ],
   "source": [
    "# gwbowv is a matrix which contains normalised document vectors.\n",
    "gwbowv = np.zeros( (train[\"news\"].size, num_clusters*(num_features)), dtype=\"float32\")\n",
    "\n",
    "counter = 0\n",
    "\n",
    "min_no = 0\n",
    "max_no = 0\n",
    "for review in train[\"news\"]:\n",
    "    # Get the wordlist in each news article.\n",
    "    result = tokenizer.parse(review).replace(\"\\u3000\",\"\").replace(\"\\n\",\"\")\n",
    "    result = re.sub(r'[0123456789０１２３４５６７８９！＠＃＄％＾＆\\-|\\\\＊\\“（）＿■×※⇒—●(：〜＋=)／*&^%$#@!~`){}…\\[\\]\\\"\\'\\”:;<>?＜＞？、。・,./『』【】「」→←○]+', \"\", result)\n",
    "    h = result.split(\" \")\n",
    "    h = filter((\"\").__ne__, h)\n",
    "    words = h\n",
    "    gwbowv[counter] = create_cluster_vector_and_gwbowv(prob_wordvecs, words, word_centroid_map, word_centroid_prob_map, num_features, word_idf_dict, featurenames, num_clusters, train=True)\n",
    "    counter+=1\n",
    "    if counter % 1000 == 0:\n",
    "        print (\"Train News Covered : \",counter)\n",
    "\n",
    "gwbowv_name = \"SDV_\" + str(num_clusters) + \"cluster_\" + str(num_features) + \"feature_matrix_gmm_sparse.npy\"\n",
    "\n",
    "gwbowv_test = np.zeros( (test[\"news\"].size, num_clusters*(num_features)), dtype=\"float32\")\n",
    "\n",
    "counter = 0\n",
    "\n",
    "for review in test[\"news\"]:\n",
    "    # Get the wordlist in each news article.\n",
    "    result = tokenizer.parse(review).replace(\"\\u3000\",\"\").replace(\"\\n\",\"\")\n",
    "    result = re.sub(r'[0123456789０１２３４５６７８９！＠＃＄％＾＆\\-|\\\\＊\\“（）＿■×※⇒—●(：〜＋=)／*&^%$#@!~`){}…\\[\\]\\\"\\'\\”:;<>?＜＞？、。・,./『』【】「」→←○]+', \"\", result)\n",
    "    h = result.split(\" \")\n",
    "    h = filter((\"\").__ne__, h)\n",
    "    words = h\n",
    "    gwbowv_test[counter] = create_cluster_vector_and_gwbowv(prob_wordvecs, words, word_centroid_map, word_centroid_prob_map, num_features, word_idf_dict, featurenames, num_clusters)\n",
    "    counter+=1\n",
    "    if counter % 1000 == 0:\n",
    "        print (\"Test News Covered : \",counter)\n",
    "\n",
    "test_gwbowv_name = \"TEST_SDV_\" + str(num_clusters) + \"cluster_\" + str(num_features) + \"feature_matrix_gmm_sparse.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = tokenizer.parse(review).replace(\"\\u3000\",\"\").replace(\"\\n\",\"\")\n",
    "result = re.sub(r'[0123456789０１２３４５６７８９！＠＃＄％＾＆\\-|\\\\＊\\“（）＿■×※⇒—●(：〜＋=)／*&^%$#@!~`){}…\\[\\]\\\"\\'\\”:;<>?＜＞？、。・,./『』【】「」→←○]+', \"\", result)\n",
    "h = result.split(\" \")\n",
    "h = filter((\"\").__ne__, h)\n",
    "words = h\n",
    "#gwbowv[counter] = create_cluster_vector_and_gwbowv(prob_wordvecs, words, word_centroid_map, word_centroid_prob_map, num_features, word_idf_dict, featurenames, num_clusters, train=True)\n",
    "#counter+=1\n",
    "#if counter % 1000 == 0:\n",
    "#    print (\"Train News Covered : \",counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1218"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gwbowv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in gwbowv:\n",
    "    print(i, len(i))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(gwbowv[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Making sparse...\")\n",
    "# Set the threshold percentage for making it sparse. \n",
    "percentage = 0.04\n",
    "min_no = min_no*1.0/len(train[\"news\"])\n",
    "max_no = max_no*1.0/len(train[\"news\"])\n",
    "print (\"Average min: \", min_no)\n",
    "print (\"Average max: \", max_no)\n",
    "thres = (abs(max_no) + abs(min_no))/2\n",
    "thres = thres*percentage\n",
    "\n",
    "# Make values of matrices which are less than threshold to zero.\n",
    "temp = abs(gwbowv) < thres\n",
    "gwbowv[temp] = 0\n",
    "\n",
    "temp = abs(gwbowv_test) < thres\n",
    "gwbowv_test[temp] = 0\n",
    "\n",
    "#saving gwbowv train and test matrices\n",
    "np.save(\"../japanese-dataset/livedoor-news-corpus/model/\"+gwbowv_name, gwbowv)\n",
    "np.save(\"../japanese-dataset/livedoor-news-corpus/model/\"+test_gwbowv_name, gwbowv_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## plot modified word vector representation\n",
    "skip=0\n",
    "limit=241 \n",
    "\n",
    "vocab = list(prob_wordvecs.keys())\n",
    "tsne_target = []\n",
    "for i in range(limit):\n",
    "    tsne_target.append(prob_wordvecs[vocab[i]])\n",
    "X = np.vstack(tsne_target)\n",
    " \n",
    "tsne_model_scdv = TSNE(n_components=2, random_state=0,verbose=2)\n",
    "np.set_printoptions(suppress=True)\n",
    "tsne_model_scdv.fit_transform(X)\n",
    "pickle.dump(tsne_model_scdv,open(\"../japanese-dataset/livedoor-news-corpus/model/tsne_scdv.pkl\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scdv_tsne = pd.DataFrame(tsne_model_scdv.embedding_[skip:limit, 0],columns = [\"x\"])\n",
    "scdv_tsne[\"y\"] = pd.DataFrame(tsne_model_scdv.embedding_[skip:limit, 1])\n",
    "scdv_tsne[\"word\"] = list(vocab)[skip:limit]\n",
    "scdv_tsne[\"cluster\"] = idx[skip:limit]\n",
    "scdv_tsne.plot.scatter(x=\"x\",y=\"y\",c=\"cluster\",cmap=\"viridis\",figsize=(8, 6),s=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import plotly\n",
    "# import plotly.plotly as py\n",
    "# import plotly.graph_objs as go\n",
    "# plotly.offline.init_notebook_mode(connected=False)\n",
    "# # Create a trace\n",
    "# trace = go.Scatter(\n",
    "#     x =tsne_model_scdv.embedding_[skip:limit, 0],\n",
    "#     y = tsne_model_scdv.embedding_[skip:limit, 1],\n",
    "#     text=list(vocab)[skip:limit],\n",
    "#     mode = 'markers+text'\n",
    "# )\n",
    "\n",
    "# data = [trace]\n",
    "\n",
    "# # Plot and embed in ipython notebook!\n",
    "# plotly.offline.iplot(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## test lgb\n",
    "from sklearn.metrics import classification_report\n",
    "import lightgbm as lgb\n",
    "\n",
    "start = time.time()\n",
    "clf = lgb.LGBMClassifier(objective=\"multiclass\")\n",
    "clf.fit(gwbowv, train[\"class\"])\n",
    "Y_true, Y_pred  = test[\"class\"], clf.predict(gwbowv_test)\n",
    "print (\"Report\")\n",
    "print (classification_report(Y_true, Y_pred, digits=6))\n",
    "print (\"Accuracy: \",clf.score(gwbowv_test,test[\"class\"]))\n",
    "print (\"Time taken:\", time.time() - start, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# res = []\n",
    "# for review in all[\"news\"]:\n",
    "#     # Get the wordlist in each news article.\n",
    "#     result = tokenizer.parse(review).replace(\"\\u3000\",\"\").replace(\"\\n\",\"\")\n",
    "#     result = re.sub(r'[0123456789０１２３４５６７８９！＠＃＄％＾＆\\-|\\\\＊\\“（）＿■×※⇒—●(：〜＋=)／*&^%$#@!~`){}…\\[\\]\\\"\\'\\”:;<>?＜＞？、。・,./『』【】「」→←○]+', \"\", result)\n",
    "#     h = result.split(\" \")\n",
    "#     h = filter((\"\").__ne__, h)\n",
    "#     words = list(h)\n",
    "#     res.append(\" \".join(words))\n",
    "# corpus = \" \".join(res)\n",
    "# f = open('../japanese-dataset/livedoor-news-corpus/for-fasttext/corpus.txt', 'w') # 書き込みモードで開く\n",
    "# f.write(corpus) # 引数の文字列をファイルに書き込む\n",
    "# f.close() # ファイルを閉じる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from gensim.models.wrappers import FastText\n",
    "# fasttext_model = FastText.load_fasttext_format('../japanese-dataset/livedoor-news-corpus/for-fasttext/fasttext_model_200dim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## fasttext\n",
    "import fasttext\n",
    "fasttext_model = fasttext.skipgram('../japanese-dataset/livedoor-news-corpus/for-fasttext/corpus.txt',\n",
    "                          '../japanese-dataset/livedoor-news-corpus/for-fasttext/fasttext_model',\n",
    "                            dim=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plain_docvec(num_features, wordlist,model,train=False):\n",
    "    # This function computes SDV feature vectors.\n",
    "    bag_of_centroids = np.zeros( num_features, dtype=\"float32\" )\n",
    "    global min_no\n",
    "    global max_no\n",
    "\n",
    "    for word in wordlist:\n",
    "        bag_of_centroids += model[word]\n",
    "\n",
    "    norm = np.sqrt(np.einsum('...i,...i', bag_of_centroids, bag_of_centroids))\n",
    "    if(norm!=0):\n",
    "        bag_of_centroids /= norm\n",
    "\n",
    "    # To make feature vector sparse, make note of minimum and maximum values.\n",
    "    if train:\n",
    "        min_no += min(bag_of_centroids)\n",
    "        max_no += max(bag_of_centroids)\n",
    "\n",
    "    return bag_of_centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# gwbowv is a matrix which contains normalised document vectors.\n",
    "num_features = 2000\n",
    "plain_fasttext = np.zeros( (train[\"news\"].size, num_features), dtype=\"float32\")\n",
    "\n",
    "counter = 0\n",
    "\n",
    "min_no = 0\n",
    "max_no = 0\n",
    "for review in tqdm(train[\"news\"]):\n",
    "    # Get the wordlist in each news article.\n",
    "    result = tokenizer.parse(review).replace(\"\\u3000\",\"\").replace(\"\\n\",\"\")\n",
    "    result = re.sub(r'[0123456789０１２３４５６７８９！＠＃＄％＾＆\\-|\\\\＊\\“（）＿■×※⇒—●(：〜＋=)／*&^%$#@!~`){}…\\[\\]\\\"\\'\\”:;<>?＜＞？、。・,./『』【】「」→←○]+', \"\", result)\n",
    "    h = result.split(\" \")\n",
    "    h = filter((\"\").__ne__, h)\n",
    "    words = list(h)\n",
    "    plain_fasttext[counter] = plain_docvec(num_features, words, model,train=True)\n",
    "    counter+=1\n",
    "\n",
    "plain_fasttext_test = np.zeros( (test[\"news\"].size, num_features), dtype=\"float32\")\n",
    "\n",
    "counter = 0\n",
    "\n",
    "for review in tqdm(test[\"news\"]):\n",
    "    # Get the wordlist in each news article.\n",
    "    result = tokenizer.parse(review).replace(\"\\u3000\",\"\").replace(\"\\n\",\"\")\n",
    "    result = re.sub(r'[0123456789０１２３４５６７８９！＠＃＄％＾＆\\-|\\\\＊\\“（）＿■×※⇒—●(：〜＋=)／*&^%$#@!~`){}…\\[\\]\\\"\\'\\”:;<>?＜＞？、。・,./『』【】「」→←○]+', \"\", result)\n",
    "    h = result.split(\" \")\n",
    "    h = filter((\"\").__ne__, h)\n",
    "    words = list(h)\n",
    "    plain_fasttext_test[counter] = plain_docvec(num_features, words, model,train=False)\n",
    "    counter+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## test lgb fasttext-average\n",
    "from sklearn.metrics import classification_report\n",
    "import lightgbm as lgb\n",
    "\n",
    "start = time.time()\n",
    "clf = lgb.LGBMClassifier(objective=\"multiclass\")\n",
    "clf.fit(plain_fasttext, train[\"class\"])\n",
    "Y_true, Y_pred  = test[\"class\"], clf.predict(plain_fasttext_test)\n",
    "print (\"Report\")\n",
    "print (classification_report(Y_true, Y_pred, digits=6))\n",
    "print (\"Accuracy: \",clf.score(plain_fasttext_test,test[\"class\"]))\n",
    "print (\"Time taken:\", time.time() - start, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SCDV based fasttext\n",
    "from gensim.models.wrappers.fasttext import FastText\n",
    "fasttext_model_200 = FastText.load_fasttext_format('../japanese-dataset/livedoor-news-corpus/for-fasttext/fasttext_model_200dim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get wordvectors for all words in vocabulary.\n",
    "word_vectors = fasttext_model_200.wv.syn0\n",
    "\n",
    "# Set number of clusters.\n",
    "num_clusters = 60\n",
    "# Uncomment below line for creating new clusters.\n",
    "idx, idx_proba = cluster_GMM(num_clusters, word_vectors)\n",
    "\n",
    "# Uncomment below lines for loading saved cluster assignments and probabaility of cluster assignments.\n",
    "# idx_name = \"gmm_latestclusmodel_len2alldata.pkl\"\n",
    "# idx_proba_name = \"gmm_prob_latestclusmodel_len2alldata.pkl\"\n",
    "# idx, idx_proba = read_GMM(idx_name, idx_proba_name)\n",
    "\n",
    "# Create a Word / Index dictionary, mapping each vocabulary word to\n",
    "# a cluster number\n",
    "word_centroid_map = dict(zip( fasttext_model_200.wv.index2word, idx ))\n",
    "# Create a Word / Probability of cluster assignment dictionary, mapping each vocabulary word to\n",
    "# list of probabilities of cluster assignments.\n",
    "word_centroid_prob_map = dict(zip( fasttext_model_200.wv.index2word, idx_proba ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_features = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pre-computing probability word-cluster vectors.\n",
    "prob_wordvecs = get_probability_word_vectors(featurenames, fasttext_model_200,word_centroid_map, num_clusters, word_idf_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## for gensim keyedvectors\n",
    "file = open('../japanese-dataset/livedoor-news-corpus/model/temp3.txt', 'w')\n",
    "string_list = [str(len(prob_wordvecs)),str(len(list(prob_wordvecs.values())[0]))]\n",
    "string_list.append(\"\\n\")\n",
    "file.writelines(\" \".join(string_list))\n",
    "for key,value in tqdm(prob_wordvecs.items()):\n",
    "    string_list = []\n",
    "    string_list.append(key)\n",
    "    for i in value:\n",
    "        string_list.append(str(i))\n",
    "    string_list.append(\"\\n\")\n",
    "    file.writelines(\" \".join(string_list))\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasttext_weighted = KeyedVectors.load_word2vec_format(\"../japanese-dataset/livedoor-news-corpus/model/temp3.txt\",binary=False)\n",
    "fasttext_weighted.save(\"../japanese-dataset/livedoor-news-corpus/model/vector-response-test/fasttext_weighted.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(prob_wordvecs,open(\"../japanese-dataset/livedoor-news-corpus/model/prob_wordvecs_fasttext.pkl\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# gwbowv is a matrix which contains normalised document vectors.\n",
    "gwbowv_fasttext = np.zeros( (train[\"news\"].size, num_clusters*(num_features)), dtype=\"float32\")\n",
    "\n",
    "counter = 0\n",
    "\n",
    "min_no = 0\n",
    "max_no = 0\n",
    "for review in train[\"news\"]:\n",
    "    # Get the wordlist in each news article.\n",
    "    result = tokenizer.parse(review).replace(\"\\u3000\",\"\").replace(\"\\n\",\"\")\n",
    "    result = re.sub(r'[0123456789０１２３４５６７８９！＠＃＄％＾＆\\-|\\\\＊\\“（）＿■×※⇒—●(：〜＋=)／*&^%$#@!~`){}…\\[\\]\\\"\\'\\”:;<>?＜＞？、。・,./『』【】「」→←○]+', \"\", result)\n",
    "    h = result.split(\" \")\n",
    "    h = filter((\"\").__ne__, h)\n",
    "    words = list(h)\n",
    "    gwbowv_fasttext[counter] = create_cluster_vector_and_gwbowv(prob_wordvecs, words, word_centroid_map, word_centroid_prob_map, num_features, word_idf_dict, featurenames, num_clusters, train=True)\n",
    "    counter+=1\n",
    "    if counter % 1000 == 0:\n",
    "        print (\"Train News Covered : \",counter)\n",
    "\n",
    "gwbowv_name = \"SDV_fasttext_\" + str(num_clusters) + \"cluster_\" + str(num_features) + \"feature_matrix_gmm_sparse.npy\"\n",
    "\n",
    "gwbowv_fasttext_test = np.zeros( (test[\"news\"].size, num_clusters*(num_features)), dtype=\"float32\")\n",
    "\n",
    "counter = 0\n",
    "\n",
    "for review in test[\"news\"]:\n",
    "    # Get the wordlist in each news article.\n",
    "    result = tokenizer.parse(review).replace(\"\\u3000\",\"\").replace(\"\\n\",\"\")\n",
    "    result = re.sub(r'[0123456789０１２３４５６７８９！＠＃＄％＾＆\\-|\\\\＊\\“（）＿■×※⇒—●(：〜＋=)／*&^%$#@!~`){}…\\[\\]\\\"\\'\\”:;<>?＜＞？、。・,./『』【】「」→←○]+', \"\", result)\n",
    "    h = result.split(\" \")\n",
    "    h = filter((\"\").__ne__, h)\n",
    "    words = list(h)\n",
    "    gwbowv_fasttext_test[counter] = create_cluster_vector_and_gwbowv(prob_wordvecs, words, word_centroid_map, word_centroid_prob_map, num_features, word_idf_dict, featurenames, num_clusters)\n",
    "    counter+=1\n",
    "    if counter % 1000 == 0:\n",
    "        print (\"Test News Covered : \",counter)\n",
    "\n",
    "test_gwbowv_name = \"TEST_SDV_fasttext_\" + str(num_clusters) + \"cluster_\" + str(num_features) + \"feature_matrix_gmm_sparse.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gwbowv_fasttext[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print (\"Making sparse...\")\n",
    "# Set the threshold percentage for making it sparse. \n",
    "percentage = 0.04\n",
    "min_no = min_no*1.0/len(train[\"news\"])\n",
    "max_no = max_no*1.0/len(train[\"news\"])\n",
    "print (\"Average min: \", min_no)\n",
    "print (\"Average max: \", max_no)\n",
    "thres = (abs(max_no) + abs(min_no))/2\n",
    "thres = thres*percentage\n",
    "\n",
    "# Make values of matrices which are less than threshold to zero.\n",
    "temp = abs(gwbowv_fasttext) < thres\n",
    "gwbowv_fasttext[temp] = 0\n",
    "\n",
    "temp = abs(gwbowv_fasttext_test) < thres\n",
    "gwbowv_fasttext_test[temp] = 0\n",
    "\n",
    "#saving gwbowv train and test matrices\n",
    "np.save(\"../japanese-dataset/livedoor-news-corpus/model/\"+gwbowv_name, gwbowv_fasttext)\n",
    "np.save(\"../japanese-dataset/livedoor-news-corpus/model/\"+test_gwbowv_name, gwbowv_fasttext_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## test lgb SCDV based fasttext\n",
    "from sklearn.metrics import classification_report\n",
    "import lightgbm as lgb\n",
    "\n",
    "start = time.time()\n",
    "clf = lgb.LGBMClassifier(objective=\"multiclass\")\n",
    "clf.fit(gwbowv_fasttext, train[\"class\"])\n",
    "Y_true, Y_pred  = test[\"class\"], clf.predict(gwbowv_fasttext_test)\n",
    "print (\"Report\")\n",
    "print (classification_report(Y_true, Y_pred, digits=6))\n",
    "print (\"Accuracy: \",clf.score(gwbowv_fasttext_test,test[\"class\"]))\n",
    "print (\"Time taken:\", time.time() - start, \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
